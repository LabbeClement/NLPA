{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3aaa7fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\clem9\\Desktop\\ecole\\ing3\\NLP\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForSequenceClassification, \n",
    "    Trainer, \n",
    "    TrainingArguments\n",
    ")\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9355d7f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 30916 articles | Test: 7730 articles\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 1. CHARGEMENT DES DONN√âES\n",
    "# ============================================\n",
    "train_df = pd.read_csv('data/train.csv')\n",
    "test_df = pd.read_csv('data/test.csv')\n",
    "\n",
    "# Garder seulement les colonnes n√©cessaires\n",
    "train_df = train_df[['text', 'label_numeric']].rename(columns={'label_numeric': 'label'})\n",
    "test_df = test_df[['text', 'label_numeric']].rename(columns={'label_numeric': 'label'})\n",
    "\n",
    "print(f\"Train: {len(train_df)} articles | Test: {len(test_df)} articles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34e9e014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 2. CONVERSION EN DATASET HUGGINGFACE\n",
    "# ============================================\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a777e23c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tokenization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30916/30916 [00:11<00:00, 2797.63 examples/s]\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7730/7730 [00:02<00:00, 2646.10 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 3. TOKENIZATION\n",
    "# ============================================\n",
    "print(\"\\nTokenization...\")\n",
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples['text'], \n",
    "        padding=\"max_length\", \n",
    "        truncation=True, \n",
    "        max_length=512\n",
    "    )\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8cb4593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Chargement du mod√®le BERT...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device utilis√©: cuda\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 4. MOD√àLE\n",
    "# ============================================\n",
    "print(\"\\nChargement du mod√®le BERT...\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name, \n",
    "    num_labels=2\n",
    ")\n",
    "\n",
    "# D√©tecter si GPU disponible\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Device utilis√©: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2508f880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 5. M√âTRIQUES D'√âVALUATION\n",
    "# ============================================\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    \n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        labels, preds, average='binary'\n",
    "    )\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    \n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f141979f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configuration de l'entra√Ænement...\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 6. CONFIGURATION DE L'ENTRA√éNEMENT\n",
    "# ============================================\n",
    "print(\"\\nConfiguration de l'entra√Ænement...\")\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=4,  # R√©duit pour GPU 8GB\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    push_to_hub=False,\n",
    "    logging_steps=100,\n",
    "    fp16=True,  # Pr√©cision mixte pour acc√©l√©rer\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4a85079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entra√Ænement en cours...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15458' max='15458' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15458/15458 50:44, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003989</td>\n",
       "      <td>0.999483</td>\n",
       "      <td>0.999528</td>\n",
       "      <td>0.999057</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001453</td>\n",
       "      <td>0.999871</td>\n",
       "      <td>0.999882</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999764</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=15458, training_loss=0.005121192545072739, metrics={'train_runtime': 3044.7436, 'train_samples_per_second': 20.308, 'train_steps_per_second': 5.077, 'total_flos': 1.626868277501952e+16, 'train_loss': 0.005121192545072739, 'epoch': 2.0})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================\n",
    "# 7. ENTRA√éNEMENT\n",
    "# ============================================\n",
    "print(\"\\nEntra√Ænement en cours...\")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221b249f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä √âvaluation finale...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "üéØ R√âSULTATS FINAUX\n",
      "==================================================\n",
      "eval_loss: 0.0015\n",
      "eval_accuracy: 0.9999\n",
      "eval_f1: 0.9999\n",
      "eval_precision: 1.0000\n",
      "eval_recall: 0.9998\n",
      "eval_runtime: 62.0637\n",
      "eval_samples_per_second: 124.5500\n",
      "eval_steps_per_second: 31.1450\n",
      "epoch: 2.0000\n",
      "\n",
      "üìà G√©n√©ration de la matrice de confusion...\n",
      "\n",
      "Matrice de confusion:\n",
      "                 Predicted\n",
      "               Fake  Real\n",
      "Actual Fake    3491     0\n",
      "       Real       1  4238\n",
      "\n",
      "üíæ Sauvegarde du mod√®le...\n",
      "\n",
      "‚úÖ Mod√®le sauvegard√© dans ./baseline_model/\n",
      "üéâ Entra√Ænement termin√© avec succ√®s!\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 8. √âVALUATION FINALE\n",
    "# ============================================\n",
    "print(\"\\n√âvaluation finale...\")\n",
    "results = trainer.evaluate()\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"R√âSULTATS FINAUX\")\n",
    "print(\"=\"*50)\n",
    "for key, value in results.items():\n",
    "    print(f\"{key}: {value:.4f}\")\n",
    "\n",
    "# ============================================\n",
    "# 9. MATRICE DE CONFUSION\n",
    "# ============================================\n",
    "print(\"\\nG√©n√©ration de la matrice de confusion...\")\n",
    "predictions = trainer.predict(test_dataset)\n",
    "preds = predictions.predictions.argmax(-1)\n",
    "labels = predictions.label_ids\n",
    "\n",
    "cm = confusion_matrix(labels, preds)\n",
    "print(\"\\nMatrice de confusion:\")\n",
    "print(\"                 Predicted\")\n",
    "print(\"               Fake  Real\")\n",
    "print(f\"Actual Fake    {cm[0][0]:4d}  {cm[0][1]:4d}\")\n",
    "print(f\"       Real    {cm[1][0]:4d}  {cm[1][1]:4d}\")\n",
    "\n",
    "# ============================================\n",
    "# 10. SAUVEGARDE\n",
    "# ============================================\n",
    "print(\"\\n Sauvegarde du mod√®le...\")\n",
    "model.save_pretrained(\"./baseline_model\")\n",
    "tokenizer.save_pretrained(\"./baseline_model\")\n",
    "\n",
    "print(\"\\n Mod√®le sauvegard√© dans ./baseline_model/\")\n",
    "print(\"Entra√Ænement termin√© avec succ√®s!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dae8996c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Test de pr√©diction sur VRAIS articles...\n",
      "\n",
      "======================================================================\n",
      " TESTS DE PR√âDICTION SUR ARTICLES COMPLETS\n",
      "======================================================================\n",
      "\n",
      "1. Breaking: Scientists at a secret lab have discovered that      eating chocolate every day can cure a...\n",
      "   ‚Üí Pr√©diction: üî¥ FAKE\n",
      "   ‚Üí Confiance: 100.00%\n",
      "\n",
      "2. PARIS (Reuters) - The Eiffel Tower, one of the world's most      iconic landmarks, celebrated its 13...\n",
      "   ‚Üí Pr√©diction: üü¢ REAL\n",
      "   ‚Üí Confiance: 100.00%\n",
      "\n",
      "3. Leaked documents reveal that Bill Gates and the WHO are planning      to implant microchips in COVID...\n",
      "   ‚Üí Pr√©diction: üî¥ FAKE\n",
      "   ‚Üí Confiance: 100.00%\n",
      "\n",
      "4. Doctors don't want you to know this simple trick! Drinking lemon      water with baking soda cures d...\n",
      "   ‚Üí Pr√©diction: üî¥ FAKE\n",
      "   ‚Üí Confiance: 100.00%\n",
      "\n",
      "======================================================================\n",
      " TESTS SUR ARTICLES R√âELS DU DATASET\n",
      "======================================================================\n",
      "\n",
      "‚úÖ Vrai: REAL\n",
      "   Article: TOKYO (Reuters) - Japanese Prime Minister Shinzo Abe is considering calling a snap election for as e...\n",
      "   Pr√©dit: üü¢ REAL (100.0%)\n",
      "\n",
      "‚úÖ Vrai: REAL\n",
      "   Article: WASHINGTON (Reuters) - President Donald Trump and Democratic leaders in the U.S. Congress have agree...\n",
      "   Pr√©dit: üü¢ REAL (100.0%)\n",
      "\n",
      "‚úÖ Vrai: FAKE\n",
      "   Article: This isn t the first punch this group of black Chicago residents have delivered to the failed Democr...\n",
      "   Pr√©dit: üî¥ FAKE (100.0%)\n",
      "\n",
      "‚úÖ Vrai: FAKE\n",
      "   Article: The many, many murders and rapes of American citizens at the hands of people who re here illegally i...\n",
      "   Pr√©dit: üî¥ FAKE (100.0%)\n",
      "\n",
      "‚úÖ Vrai: FAKE\n",
      "   Article: For those of us who watched the shameful MSNBC  prime time  Trump town hall event with the growing s...\n",
      "   Pr√©dit: üî¥ FAKE (100.0%)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================\n",
    "# 11. TEST DE PR√âDICTION - VERSION CORRIG√âE\n",
    "# ============================================\n",
    "print(\"\\n Test de pr√©diction sur VRAIS articles...\")\n",
    "\n",
    "def predict_news(text):\n",
    "    \"\"\"Pr√©dire si une news est fake ou real\"\"\"\n",
    "    inputs = tokenizer(\n",
    "        text, \n",
    "        return_tensors=\"pt\", \n",
    "        truncation=True, \n",
    "        max_length=512,\n",
    "        padding=True\n",
    "    )\n",
    "    \n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    model.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "        pred = torch.argmax(probs).item()\n",
    "        confidence = probs[0][pred].item()\n",
    "    \n",
    "    label = \"üî¥ FAKE\" if pred == 0 else \"üü¢ REAL\"\n",
    "    return label, confidence\n",
    "\n",
    "# ============================================\n",
    "# EXEMPLES DE VRAIS ARTICLES (pas de phrases courtes)\n",
    "# ============================================\n",
    "test_examples = [\n",
    "    # FAKE NEWS (style sensationnaliste)\n",
    "    \"\"\"Breaking: Scientists at a secret lab have discovered that \n",
    "    eating chocolate every day can cure all types of cancer and \n",
    "    make you live forever! The pharmaceutical industry is hiding \n",
    "    this information because they want to keep selling expensive \n",
    "    treatments. Share this before it gets deleted!\"\"\",\n",
    "    \n",
    "    # REAL NEWS (style journalistique)\n",
    "    \"\"\"PARIS (Reuters) - The Eiffel Tower, one of the world's most \n",
    "    iconic landmarks, celebrated its 134th anniversary today. Built \n",
    "    in 1889 by engineer Gustave Eiffel, the 324-meter iron structure \n",
    "    attracts millions of visitors annually and remains a symbol of \n",
    "    French culture and engineering excellence.\"\"\",\n",
    "    \n",
    "    # FAKE NEWS (complot)\n",
    "    \"\"\"Leaked documents reveal that Bill Gates and the WHO are planning \n",
    "    to implant microchips in COVID vaccines to control the population. \n",
    "    The mainstream media refuses to report this shocking truth. Wake up \n",
    "    people! They're tracking your every move and reading your thoughts!\"\"\",\n",
    "    \n",
    "    # FAKE NEWS (sant√©)\n",
    "    \"\"\"Doctors don't want you to know this simple trick! Drinking lemon \n",
    "    water with baking soda cures diabetes in just 3 days. Big Pharma \n",
    "    hates this because it costs only $2. Thousands of people have already \n",
    "    been cured. Try it now before the government bans this information!\"\"\",\n",
    "]\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\" TESTS DE PR√âDICTION SUR ARTICLES COMPLETS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for i, example in enumerate(test_examples, 1):\n",
    "    label, confidence = predict_news(example)\n",
    "    \n",
    "    # Afficher un extrait\n",
    "    preview = example[:100].replace(\"\\n\", \" \") + \"...\"\n",
    "    print(f\"\\n{i}. {preview}\")\n",
    "    print(f\"   ‚Üí Pr√©diction: {label}\")\n",
    "    print(f\"   ‚Üí Confiance: {confidence:.2%}\")\n",
    "\n",
    "# ============================================\n",
    "# TEST AVEC DES VRAIS ARTICLES DU DATASET\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\" TESTS SUR ARTICLES R√âELS DU DATASET\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Prendre quelques exemples du test set\n",
    "sample_articles = test_df.sample(5, random_state=42)\n",
    "\n",
    "for idx, row in sample_articles.iterrows():\n",
    "    label, confidence = predict_news(row['text'])\n",
    "    true_label = \"FAKE\" if row['label'] == 0 else \"REAL\"\n",
    "    \n",
    "    # Extraire le titre ou d√©but\n",
    "    preview = row['text'][:100].replace(\"\\n\", \" \") + \"...\"\n",
    "    \n",
    "    match = \"‚úÖ\" if label.replace(\"üî¥ \", \"\").replace(\"üü¢ \", \"\") == true_label else \"‚ùå\"\n",
    "    print(f\"\\n{match} Vrai: {true_label}\")\n",
    "    print(f\"   Article: {preview}\")\n",
    "    print(f\"   Pr√©dit: {label} ({confidence:.1%})\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3cee626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " DIAGNOSTIC APPROFONDI...\n",
      "\n",
      " V√©rification des labels:\n",
      "Label 0 = 3491 articles\n",
      "Label 1 = 4239 articles\n",
      "\n",
      "Rappel: Label 0 = FAKE, Label 1 = REAL\n",
      "\n",
      " Test sur exemples r√©els du dataset:\n",
      "\n",
      " FAKE NEWS du dataset:\n",
      "‚úÖ Vrai: FAKE | Pr√©dit: üî¥ FAKE (100.0%)\n",
      "‚úÖ Vrai: FAKE | Pr√©dit: üî¥ FAKE (100.0%)\n",
      "‚úÖ Vrai: FAKE | Pr√©dit: üî¥ FAKE (100.0%)\n",
      "‚úÖ Vrai: FAKE | Pr√©dit: üî¥ FAKE (100.0%)\n",
      "‚úÖ Vrai: FAKE | Pr√©dit: üî¥ FAKE (100.0%)\n",
      "\n",
      "REAL NEWS du dataset:\n",
      "‚úÖ Vrai: REAL | Pr√©dit: üü¢ REAL (100.0%)\n",
      "‚úÖ Vrai: REAL | Pr√©dit: üü¢ REAL (100.0%)\n",
      "‚úÖ Vrai: REAL | Pr√©dit: üü¢ REAL (100.0%)\n",
      "‚úÖ Vrai: REAL | Pr√©dit: üü¢ REAL (100.0%)\n",
      "‚úÖ Vrai: REAL | Pr√©dit: üü¢ REAL (100.0%)\n",
      "\n",
      " V√©rification des logits bruts:\n",
      "Logits bruts: tensor([[ 5.6953, -5.2773]], device='cuda:0')\n",
      "Probabilit√©s: Fake=1.0000, Real=0.0000\n",
      "Pr√©diction: 0 (0=Fake, 1=Real)\n",
      "\n",
      " Statistiques sur TOUT le test set (√©chantillon de 100):\n",
      "\n",
      "Accuracy sur 100 exemples: 100.00%\n",
      "\n",
      "Matrice de confusion:\n",
      "              Predicted\n",
      "            Fake  Real\n",
      "Actual Fake   51     0\n",
      "       Real    0    49\n",
      "\n",
      " Distribution des pr√©dictions:\n",
      "Pr√©dit FAKE: 51/100 (51%)\n",
      "Pr√©dit REAL: 49/100 (49%)\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# DIAGNOSTIC DU MOD√àLE\n",
    "# ============================================\n",
    "print(\"\\n DIAGNOSTIC APPROFONDI...\")\n",
    "\n",
    "# 1. V√©rifier les labels du dataset\n",
    "print(\"\\n V√©rification des labels:\")\n",
    "print(f\"Label 0 = {test_df[test_df['label'] == 0]['label'].count()} articles\")\n",
    "print(f\"Label 1 = {test_df[test_df['label'] == 1]['label'].count()} articles\")\n",
    "print(\"\\nRappel: Label 0 = FAKE, Label 1 = REAL\")\n",
    "\n",
    "# 2. Tester sur des exemples du test set r√©el\n",
    "print(\"\\n Test sur exemples r√©els du dataset:\")\n",
    "\n",
    "# Prendre 5 fake et 5 real du test set\n",
    "fake_samples = test_df[test_df['label'] == 0].sample(5)\n",
    "real_samples = test_df[test_df['label'] == 1].sample(5)\n",
    "\n",
    "print(\"\\n FAKE NEWS du dataset:\")\n",
    "for idx, row in fake_samples.iterrows():\n",
    "    label, conf = predict_news(row['text'])\n",
    "    true_label = \"FAKE\" if row['label'] == 0 else \"REAL\"\n",
    "    match = \"‚úÖ\" if label.replace(\"üî¥ \", \"\").replace(\"üü¢ \", \"\") == true_label else \"‚ùå\"\n",
    "    print(f\"{match} Vrai: {true_label} | Pr√©dit: {label} ({conf:.1%})\")\n",
    "\n",
    "print(\"\\nREAL NEWS du dataset:\")\n",
    "for idx, row in real_samples.iterrows():\n",
    "    label, conf = predict_news(row['text'])\n",
    "    true_label = \"FAKE\" if row['label'] == 0 else \"REAL\"\n",
    "    match = \"‚úÖ\" if label.replace(\"üî¥ \", \"\").replace(\"üü¢ \", \"\") == true_label else \"‚ùå\"\n",
    "    print(f\"{match} Vrai: {true_label} | Pr√©dit: {label} ({conf:.1%})\")\n",
    "\n",
    "# 3. V√©rifier les logits bruts\n",
    "print(\"\\n V√©rification des logits bruts:\")\n",
    "test_text = \"The Eiffel Tower is in Paris, France.\"\n",
    "inputs = tokenizer(test_text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    probs = torch.nn.functional.softmax(logits, dim=-1)\n",
    "    \n",
    "    print(f\"Logits bruts: {logits}\")\n",
    "    print(f\"Probabilit√©s: Fake={probs[0][0]:.4f}, Real={probs[0][1]:.4f}\")\n",
    "    print(f\"Pr√©diction: {torch.argmax(probs).item()} (0=Fake, 1=Real)\")\n",
    "\n",
    "# 4. Statistiques globales sur tout le test set\n",
    "print(\"\\n Statistiques sur TOUT le test set (√©chantillon de 100):\")\n",
    "sample_test = test_df.sample(100, random_state=42)\n",
    "predictions = []\n",
    "true_labels = []\n",
    "\n",
    "for idx, row in sample_test.iterrows():\n",
    "    label, conf = predict_news(row['text'])\n",
    "    pred = 0 if \"FAKE\" in label else 1\n",
    "    predictions.append(pred)\n",
    "    true_labels.append(row['label'])\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "acc = accuracy_score(true_labels, predictions)\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "\n",
    "print(f\"\\nAccuracy sur 100 exemples: {acc:.2%}\")\n",
    "print(\"\\nMatrice de confusion:\")\n",
    "print(f\"              Predicted\")\n",
    "print(f\"            Fake  Real\")\n",
    "print(f\"Actual Fake {cm[0][0]:4d}  {cm[0][1]:4d}\")\n",
    "print(f\"       Real {cm[1][0]:4d}  {cm[1][1]:4d}\")\n",
    "\n",
    "print(f\"\\n Distribution des pr√©dictions:\")\n",
    "fake_pred = sum(1 for p in predictions if p == 0)\n",
    "real_pred = sum(1 for p in predictions if p == 1)\n",
    "print(f\"Pr√©dit FAKE: {fake_pred}/100 ({fake_pred}%)\")\n",
    "print(f\"Pr√©dit REAL: {real_pred}/100 ({real_pred}%)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
